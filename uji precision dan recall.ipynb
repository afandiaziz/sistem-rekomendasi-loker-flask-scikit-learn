{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8acc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import date\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c384e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    stopword = StopWordRemoverFactory().create_stop_word_remover()\n",
    "\n",
    "    def cleansing(row):\n",
    "        text = re.sub(r'&[^\\s;&]+;', '', unescape(row['text']))\n",
    "        html_pattern = re.compile('<.*?>')\n",
    "        text = html_pattern.sub(r' ', text)\n",
    "        text = re.sub(\n",
    "            r'((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', text)\n",
    "        return text\n",
    "    \n",
    "    def caseFolding(row):\n",
    "        text = row['text'].lower()\n",
    "        return text\n",
    "\n",
    "    def tokenizing(row):\n",
    "        tokenized = word_tokenize(str(row['text']))\n",
    "        return tokenized\n",
    "\n",
    "    def stemming(row):\n",
    "        stemmed = [stemmer.stem(token) for token in row['text']]\n",
    "        stemmed = \" \".join(stemmed)\n",
    "        return stemmed\n",
    "\n",
    "    def stopwording(row):\n",
    "        stopworded = stopword.remove(row['text'])\n",
    "        return stopworded\n",
    "\n",
    "    data['text'] = data.apply(cleansing, axis=1)\n",
    "    data['text'] = data.apply(caseFolding, axis=1)\n",
    "    data['text'] = data.apply(tokenizing, axis=1)\n",
    "    data['text'] = data.apply(stemming, axis=1)\n",
    "    data['text'] = data.apply(stopwording, axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9774fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancies = [\n",
    "    \"Lowongan Kerja Web Developer di Perusahaan ABC\",\n",
    "    \"Dibutuhkan Software Engineer untuk Proyek Inovatif\",\n",
    "    \"Lowongan Kerja Data Analyst dengan Gaji Menarik\",\n",
    "    \"Dicari UI/UX Designer berpengalaman untuk Startup\",\n",
    "    \"Lowongan Kerja Mobile App Developer Full-time\",\n",
    "    \"Dibutuhkan Software Engineer dengan pengalaman di bidang pengembangan web.\",\n",
    "    \"Dicari UI/UX Designer yang kreatif dan berpengalaman.\",\n",
    "    \"Perusahaan mencari Data Scientist untuk menganalisis data dan membuat model prediktif.\",\n",
    "    \"Dibutuhkan Digital Marketing Specialist untuk mengelola kampanye pemasaran online.\",\n",
    "    \"Perusahaan mencari Product Manager yang memiliki pengalaman di industri teknologi.\",\n",
    "    \"Dicari Content Writer yang kreatif dan mampu menulis konten berkualitas.\",\n",
    "    \"Perusahaan membutuhkan Frontend Developer untuk mengembangkan antarmuka pengguna.\",\n",
    "    \"Dibutuhkan HR Manager dengan pengalaman dalam manajemen sumber daya manusia.\",\n",
    "    \"Dicari Graphic Designer yang mampu menciptakan desain visual yang menarik.\",\n",
    "    \"Perusahaan mencari Business Analyst untuk menganalisis kebutuhan bisnis.\",\n",
    "    \"Dibutuhkan Sales Executive untuk menjalin hubungan bisnis dengan klien.\",\n",
    "    \"Dicari Full Stack Developer yang memiliki pengetahuan luas tentang teknologi terkini.\",\n",
    "    \"Perusahaan membutuhkan Customer Service Representative yang ramah dan efisien.\",\n",
    "    \"Dibutuhkan Project Manager untuk mengelola proyek dan tim dengan baik.\",\n",
    "    \"Dicari Social Media Specialist untuk mengelola kehadiran online perusahaan.\",\n",
    "    \"Perusahaan mencari Android Developer yang berpengalaman dalam pengembangan aplikasi.\",\n",
    "    \"Dibutuhkan Accountant untuk mengelola keuangan perusahaan.\",\n",
    "    \"Dicari Network Administrator yang memiliki pemahaman tentang jaringan komputer.\",\n",
    "    \"Perusahaan membutuhkan Legal Counsel untuk memberikan nasihat hukum.\",\n",
    "    \"Dibutuhkan UI/UX Researcher untuk mengumpulkan dan menganalisis data pengguna.\"\n",
    "]\n",
    "itemPerPage = 5\n",
    "page = 1\n",
    "minWeight = 0.15\n",
    "keyword = \"DIBUTUHKAN Untuk\"\n",
    "\n",
    "\n",
    "dframeVacancies = pd.DataFrame(vacancies, columns=[\"text\"])\n",
    "dframeVacancies = dframeVacancies.dropna()\n",
    "dframeVacancies = preprocessing(dframeVacancies)\n",
    "\n",
    "dframeKeyword = pd.DataFrame([keyword], columns=[\"text\"])\n",
    "dframeKeyword = preprocessing(dframeKeyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52882692",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(dframeVacancies['text'])\n",
    "new_tfidf_vector = vectorizer.transform(dframeKeyword[\"text\"])\n",
    "\n",
    "vectorizerWithoutNorm = TfidfVectorizer(norm=None)\n",
    "tfidf_matrixWithoutNorm = vectorizerWithoutNorm.fit_transform(dframeVacancies['text'])\n",
    "new_tfidf_vectorWithoutNorm = vectorizerWithoutNorm.transform(dframeKeyword[\"text\"])\n",
    "\n",
    "countVectorizer = CountVectorizer()\n",
    "tf = countVectorizer.fit_transform(dframeVacancies['text'])\n",
    "tf_keyword = countVectorizer.transform(dframeKeyword[\"text\"])\n",
    "\n",
    "document_frequencies = tfidf_matrix.astype(bool).sum(axis=0).A1\n",
    "words = vectorizer.get_feature_names_out()\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "document_frequenciesWithoutNorm = tfidf_matrixWithoutNorm.astype(bool).sum(axis=0).A1\n",
    "wordsWithoutNorm = vectorizerWithoutNorm.get_feature_names_out()\n",
    "idf_valuesWithoutNorm = vectorizerWithoutNorm.idf_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
